from collections import OrderedDict
from json.decoder import JSONDecodeError
from urllib.parse import urljoin
from typing import Tuple, Optional, Union, Any, Dict, List

import requests
from bs4 import BeautifulSoup

from ._exception_handling import ExceptionHandlingMetaclass
from ._schemaorg import SchemaOrg
from ._decorators import Decorators


# some sites close their content for 'bots', so user-agent must be supplied
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7"
}


class AbstractScraper(metaclass=ExceptionHandlingMetaclass):
    def __init__(
        self,
        url,
        exception_handling: bool = True,
        meta_http_equiv: bool = False,
        proxies: Optional[str] = None,  # allows us to specify optional proxy server
        test: bool = False,
        timeout: Union[
            float, Tuple, None
        ] = None,  # allows us to specify optional timeout for request
        wild_mode: bool = False,
    ):
        if test:  # when testing, we load a file
            page_data = url.read()
            url = None
        else:
            page_data = requests.get(
                url, headers=HEADERS, proxies=proxies, timeout=timeout
            ).content

        self.wild_mode = wild_mode
        self.exception_handling = exception_handling
        self.meta_http_equiv = meta_http_equiv
        self.soup = BeautifulSoup(page_data, "html.parser")
        self.url = url

        # Attempt to read Schema.org data. Gracefully fail if it raises an exception parsing the JSON.
        # The scraper subclass can use BeautifulSoup to extract the information.
        try:
            self.schema = SchemaOrg(page_data)
        except JSONDecodeError:
            pass

    @classmethod
    def host(cls) -> str:
        """ get the host of the url, so we can use the correct scraper """
        raise NotImplementedError("This should be implemented.")

    def canonical_url(self):
        canonical_link = self.soup.find("link", {"rel": "canonical", "href": True})
        if canonical_link:
            return urljoin(self.url, canonical_link["href"])
        return self.url

    @Decorators.normalize_string_output
    @Decorators.schema_org_priority
    def title(self) -> Optional[str]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def total_time(self) -> Optional[int]:
        """ total time it takes to preparate the recipe in minutes """
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def yields(self) -> Optional[int]:
        """ The number of servings or items in the recipe """
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    @Decorators.og_image_get
    def image(self) -> Optional[str]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def nutrients(self) -> Optional[Dict[str, Any]]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.bcp47_validate
    @Decorators.schema_org_priority
    def language(self) -> Optional[str]:
        """
        Human language the recipe is written in.

        May be overridden by individual scrapers.
        """
        candidate_languages = OrderedDict()
        html = self.soup.find("html", {"lang": True})
        candidate_languages[html.get("lang")] = True

        # Deprecated: check for a meta http-equiv header
        # See: https://www.w3.org/International/questions/qa-http-and-lang
        meta_language = (
            self.soup.find(
                "meta",
                {
                    "http-equiv": lambda x: x and x.lower() == "content-language",
                    "content": True,
                },
            )
            if self.meta_http_equiv
            else None
        )
        if meta_language:
            language = meta_language.get("content").split(",", 1)[0]
            if language:
                candidate_languages[language] = True

        # If other langs exist, remove 'en' commonly generated by HTML editors
        if len(candidate_languages) > 1:
            candidate_languages.pop("en", None)

        # Return the first candidate language
        return candidate_languages.popitem(last=False)[0]

    @Decorators.schema_org_priority
    def ingredients(self) -> Optional[List[str]]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def joined_instructions(self) -> Optional[str]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def ratings(self) -> Optional[float]:
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def author(self) -> Optional[str]:
        raise NotImplementedError("This should be implemented.")

    def reviews(self) -> Optional[Any]:
        raise NotImplementedError("This should be implemented.")

    def links(self) -> Optional[List[str]]:
        invalid_href = {"#", ""}
        links_html = self.soup.findAll("a", href=True)

        return [link.attrs for link in links_html if link["href"] not in invalid_href]

    def site_name(self) -> Optional[str]:
        meta = self.soup.find("meta", property="og:site_name")
        return meta.get("content") if meta else None
